<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Assignments</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #111827; /* bg-gray-900 */
            color: #d1d5db; /* text-gray-300 */
        }
        .gradient-text {
            background-image: linear-gradient(to right, #6ee7b7, #60a5fa);
            -webkit-background-clip: text;
            background-clip: text;
            color: transparent;
        }
        /* Page container styles */
        .page {
            display: none; /* Hide all pages by default */
        }
        .page.active {
            display: block; /* Show only the active page */
        }
        /* Styles for Assignment Page */
        .explanation-content {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.7s ease-in-out, padding-top 0.5s ease-in-out, margin-top 0.5s ease-in-out;
            padding-top: 0;
            margin-top: 0;
        }
        .question-card.open .explanation-content {
            max-height: 800px; /* Increased for more detailed content */
            padding-top: 1rem;
            margin-top: 1rem;
        }
        .question-card.open .toggle-icon {
            transform: rotate(180deg);
        }
        .toggle-icon {
            transition: transform 0.3s ease-in-out;
        }
        /* Nav button active style */
        .nav-button.active {
            background-color: #3b82f6;
            color: white;
        }
        /* Dropdown styles */
        .dropdown {
            position: relative;
            display: inline-block;
        }
        .dropdown-content {
            display: none;
            position: absolute;
            background-color: #1f2937;
            min-width: 160px;
            box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);
            z-index: 51; /* Ensure it's above other content */
            border-radius: 0.5rem;
            padding: 0.5rem 0;
            max-height: 300px;
            overflow-y: auto;
        }
        .dropdown-content a:hover { background-color: #374151; }
        .dropdown:hover .dropdown-content { display: block; }
        
        /* Home page week card style */
        .week-card {
            background-color: #1f2937;
            border: 1px solid #374151;
            transition: transform 0.2s ease-in-out, box-shadow 0.2s ease-in-out;
        }
        .week-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 15px -3px rgba(59, 130, 246, 0.1), 0 4px 6px -2px rgba(59, 130, 246, 0.05);
        }
        .week-card.disabled {
            background-color: #374151;
            cursor: not-allowed;
            opacity: 0.6;
        }
        .week-card.disabled:hover {
            transform: none;
            box-shadow: none;
        }
    </style>
</head>
<body>

    <!-- Navigation Bar -->
    <nav class="bg-gray-800/80 backdrop-blur-sm sticky top-0 z-50">
        <div class="container mx-auto px-4">
            <div class="flex items-center justify-center h-16">
                <div class="flex space-x-2 md:space-x-4">
                    <button data-page="home" class="nav-button px-3 py-2 rounded-md text-sm font-medium text-gray-300 hover:bg-gray-700 hover:text-white">Home</button>
                    <div class="dropdown">
                        <button class="nav-button px-3 py-2 rounded-md text-sm font-medium text-gray-300 hover:bg-gray-700 hover:text-white" data-page="assignments">Assignments <i class="fas fa-chevron-down ml-1 text-xs"></i></button>
                        <div id="quiz-dropdown" class="dropdown-content">
                            <!-- Dropdown links will be inserted here -->
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </nav>

    <!-- Page 0: Home -->
    <div id="page-home" class="page">
        <header class="text-center py-12 md:py-16">
            <h1 class="text-4xl md:text-6xl font-bold gradient-text">LLM Course Companion</h1>
            <p class="mt-4 text-lg text-gray-400 max-w-2xl mx-auto">Your central hub for weekly assignments.</p>
        </header>
        <main class="container mx-auto px-4 pb-16">
            <h2 class="text-2xl font-bold text-center text-white mb-8">Select a Week to Begin</h2>
            <div id="home-grid" class="grid grid-cols-2 md:grid-cols-3 lg:grid-cols-4 gap-6 max-w-5xl mx-auto">
                <!-- Week cards will be inserted here -->
            </div>
        </main>
    </div>

    <!-- Page 1: Assignments -->
    <div id="page-assignments" class="page">
        <header class="text-center py-10 md:py-12 px-4">
            <h1 id="quiz-title" class="text-3xl md:text-5xl font-bold gradient-text tracking-tight"></h1>
            <p class="mt-3 text-lg text-gray-400 max-w-2xl mx-auto">Answers are shown below. Click a card to reveal the explanation.</p>
        </header>
        <main id="quiz-container" class="container mx-auto px-4 pb-16">
            <!-- Quiz content will be inserted here -->
        </main>
    </div>

    <script>
        // --- DATA FOR ALL PAGES ---
        const allQuizData = {
            week1: [
                { question: "Which of the following best demonstrates the principle of distributional semantics?", options: ["Words that co-occur frequently tend to share semantic properties.", "Each word has a unique, fixed meaning regardless of context.", "Syntax determines the entire meaning of a sentence.", "Distributional semantics is unrelated to word embeddings."], correctAnswer: "Words that co-occur frequently tend to share semantic properties.", explanation: "<b>Fundamental Concept: The Distributional Hypothesis.</b> This is the core idea that a word's meaning is defined by the words it tends to appear with. Think of 'coffee' and 'tea'. They often appear in similar contexts ('cup of ___', 'drink ___', 'hot ___'), so we can infer they have similar semantic properties (they are both hot beverages).<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> The chosen answer is a direct statement of this hypothesis.<br>• <b>Incorrect:</b> 'Each word has a unique, fixed meaning...' contradicts this by ignoring context. 'Syntax determines the entire meaning...' is wrong because syntax is about grammar, not word meaning from context. '...unrelated to word embeddings' is false because word embeddings are a computational method for *implementing* the distributional hypothesis." },
                { question: "Which of the following words is least likely to be polysemous?", options: ["Bank", "Tree", "Gravity", "Idea"], correctAnswer: "Gravity", explanation: "<b>Fundamental Concept: Polysemy.</b> A word is polysemous if it has multiple, distinct but related meanings. The key is to identify which word has the most specific and least ambiguous primary meaning.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> 'Gravity' overwhelmingly refers to the single, specific physical force. While it can be used metaphorically ('gravity of the situation'), this is a figurative extension, not a separate core meaning.<br>• <b>Incorrect:</b> 'Bank' can be a river bank or a financial institution. 'Tree' can be a plant or a data structure. 'Idea' can be a plan, a concept, or a belief. These all have multiple distinct meanings, making them highly polysemous." },
                { question: "Consider the following sentence pair: Sentence 1: Riya dropped the glass. Sentence 2: The glass broke. Does Sentence 1 entail Sentence 2?", options: ["Yes", "No"], correctAnswer: "No", explanation: "<b>Fundamental Concept: Logical Entailment.</b> Entailment is a strict, logical relationship. Statement A entails statement B if and only if the truth of A *guarantees* the truth of B in all possible worlds. It is about certainty, not probability.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> 'No' is correct because while it's highly probable a dropped glass will break, it is not a logical certainty. We can imagine a world where the glass is made of durable material or lands on a soft pillow. Since a scenario exists where S1 is true and S2 is false, there is no entailment.<br>• <b>Incorrect:</b> Choosing 'Yes' confuses real-world likelihood with logical necessity. This is a key distinction in formal semantics." },
                { question: "Which sentence contains a homonym?", options: ["He wound the clock before bed.", "She tied her hair in a bun.", "I can't bear the noise.", "He likes to bat after lunch."], correctAnswer: "He likes to bat after lunch.", explanation: "<b>Fundamental Concept: Homonyms vs. Polysemy.</b> Homonyms are words that have the same spelling and pronunciation but different and *unrelated* origins and meanings. Polysemy involves a single word with multiple *related* meanings.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> 'Bat' (a flying mammal) and 'bat' (sporting equipment) have completely unrelated origins, making them a classic example of a homonym.<br>• <b>Incorrect:</b> 'Wound' (injury) and 'wound' (past tense of wind) are homographs (same spelling, different pronunciation). 'Bear' (the animal) and 'bear' (to endure) is another good example of a homonym, but 'bat' is the intended answer. 'Bun' (hairstyle vs. bread) is arguably polysemous as both relate to a rounded shape." },
                { question: "Which of the following relationships are incorrectly labeled?", options: ["Car is a meronym of wheel.", "Rose is a hyponym of flower.", "Keyboard is a holonym of key.", "Tree is a hypernym of oak."], correctAnswer: "Car is a meronym of wheel.", explanation: "<b>Fundamental Concept: Lexical Relations.</b> This question tests two key pairs of relationships:<br>1. <b>Meronymy/Holonymy:</b> The 'part-of' relationship. A meronym is the part, and a holonym is the whole.<br>2. <b>Hyponymy/Hypernymy:</b> The 'is-a' relationship. A hyponym is a specific instance, and a hypernym is the general category.<br><br><b>Applying the Concept:</b><br>• <b>Correct (Incorrectly Labeled):</b> A 'wheel' is a part of a 'car'. Therefore, 'wheel' is the meronym and 'car' is the holonym. The statement reverses this.<br>• <b>Incorrect (Correctly Labeled):</b> A 'rose' is a type of 'flower' (hyponym). A 'keyboard' is the whole that contains a 'key' (holonym). A 'tree' is a general category for an 'oak' (hypernym)." },
                { question: "___ studies how context influences the interpretation of meaning.", options: ["Syntax", "Morphology", "Pragmatics", "Semantics"], correctAnswer: "Pragmatics", explanation: "<b>Fundamental Concept: Levels of Linguistic Analysis.</b> It's crucial to distinguish between different fields of linguistics.<br>• <b>Semantics:</b> The study of literal, 'dictionary' meaning.<br>• <b>Pragmatics:</b> The study of 'meaning in context' or 'speaker meaning'. It asks not just 'What do the words mean?', but 'What did the speaker *mean* by saying those words in this situation?'<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> The question explicitly asks about the influence of context, which is the definition of pragmatics.<br>• <b>Incorrect:</b> Syntax is about sentence structure. Morphology is about word structure." },
                { question: "In the sentence, \"After Sita praised Radha, she smiled happily,\" who does \"she\" most likely refer to?", options: ["Sita", "Radha", "Ambiguous", "Neither"], correctAnswer: "Ambiguous", explanation: "<b>Fundamental Concept: Anaphora Resolution.</b> Anaphora is the use of an expression (like a pronoun) to refer back to something else mentioned in the text (the antecedent). The task of figuring out what the pronoun refers to is called anaphora resolution. Sometimes, a pronoun has more than one grammatically valid antecedent, leading to ambiguity.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> The pronoun 'she' could grammatically refer to either 'Sita' (the one doing the praising) or 'Radha' (the one being praised). Without more context, there is no way to be certain. This is a classic example of pronoun ambiguity that challenges NLP systems." },
                { question: "Which of the following statements is true? (i) Word embeddings capture semantic similarity through context. (ii) Morphological analysis is irrelevant in LLMs. (iii) Hypernyms are more specific than hyponyms.", options: ["Only (i)", "Only (i) and (iii)", "Only (ii) and (iii)", "All of the above"], correctAnswer: "Only (i)", explanation: "<b>Fundamental Concepts:</b> This question tests three distinct concepts.<br>1. <b>Word Embeddings:</b> Based on the distributional hypothesis, they represent words as vectors where similar vectors indicate similar meanings based on context.<br>2. <b>Morphology:</b> The study of word parts (stems, prefixes, suffixes).<br>3. <b>Hyponymy/Hypernymy:</b> The 'is-a' relationship (specific vs. general).<br><br><b>Applying the Concepts:</b><br>• <b>(i) is True:</b> This is the definition of how word embeddings work.<br>• <b>(ii) is False:</b> Morphology is highly relevant. LLMs use subword tokenization (like BPE) to handle rare or unknown words by breaking them into known morphological parts.<br>• <b>(iii) is False:</b> The relationship is reversed. Hypernyms are general ('animal'), and hyponyms are specific ('cat')." },
                { question: "What issues can be observed in the following text? On a much-needed #workcation in beautiful Goa. Workin & chillin by d waves!", options: ["Idioms", "Non-standard English", "Tricky Entity Names", "Neologisms"], correctAnswer: ["Non-standard English", "Neologisms"], explanation: "<b>Fundamental Concepts: Challenges in Text Processing.</b> Real-world text is messy and contains phenomena that challenge simple NLP pipelines.<br>• <b>Non-standard English:</b> Deviations from formal grammar and spelling, including slang, abbreviations, and phonetic spellings.<br>• <b>Neologisms:</b> Newly created words that are not yet in standard dictionaries.<br><br><b>Applying the Concepts:</b><br>• <b>Correct:</b> The text shows non-standard forms ('Workin', 'chillin', 'd') and a neologism ('#workcation').<br>• <b>Incorrect:</b> An idiom is a phrase with a non-literal meaning (e.g., 'it's raining cats and dogs'), which is not present here." },
                { question: "In semantic role labelling, we determine the semantic role of each argument with respect to the ___ of the sentence.", options: ["noun phrase", "subject", "predicate", "adjunct"], correctAnswer: "predicate", explanation: "<b>Fundamental Concept: Semantic Role Labeling (SRL).</b> The goal of SRL is to identify the underlying semantic structure of a sentence by answering 'Who did what to whom, where, when, how?'. The 'what'—the action, event, or state—is the central pivot around which everything else is defined. This central element is the <b>predicate</b> (typically the main verb).<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> All semantic roles (Agent, Patient, Instrument, etc.) are defined by their relationship to the predicate.<br>• <b>Incorrect:</b> Noun phrases and subjects are usually the entities that *fill* these roles; they are not the reference point." }
            ],
            week2: [
                { question: "Which of the following does not directly affect perplexity?", options: ["Vocabulary size", "Sentence probability", "Number of tokens", "Sentence length"], correctAnswer: "Vocabulary size", explanation: "<b>Fundamental Concept: Perplexity Formula.</b> Perplexity (PP) measures how well a language model predicts a sample. Its formula is `PP(W) = P(W)^(-1/N)`, where `P(W)` is the probability of the sentence and `N` is the number of tokens. The key is to distinguish between variables *in the formula* and factors that *influence* those variables.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> 'Vocabulary size' is not a variable in the perplexity formula. A larger vocabulary makes the modeling task harder and will likely lead to a lower sentence probability `P(W)`, thus increasing perplexity, but it does not *directly* feature in the calculation.<br>• <b>Incorrect:</b> 'Sentence probability' and 'Number of tokens' (which is the same as 'Sentence length' in this context) are the two explicit variables used to calculate perplexity." },
                { question: "Which equation expresses the chain rule for a 4-word sentence?", options: ["P(w1,w2,w3,w4)=P(w1)+P(w2|w1)+P(w3|w2)+P(w4|w3)", "P(w1,w2,w3,w4)=P(w1)×P(w2|w1)×P(w3|w1,w2)×P(w4|w1,w2,w3)", "P(w1,w2,w3,w4)=P(w1)×P(w2|w1)×P(w3|w2)×P(w4|w3)", "P(w1,w2,w3,w4)=P(w4|w3)*P(w3|w2)*P(w2|w1)×P(w1)"], correctAnswer: "P(w1,w2,w3,w4)=P(w1)×P(w2|w1)×P(w3|w1,w2)×P(w4|w1,w2,w3)", explanation: "<b>Fundamental Concept: The Chain Rule of Probability.</b> This rule provides a way to calculate the joint probability of a sequence of events. It states that the probability of the entire sequence is the product of the probabilities of each event, conditioned on all the events that occurred before it.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> This option perfectly represents the chain rule: P(w1) * P(w2 given w1) * P(w3 given w1 and w2) * P(w4 given w1, w2, and w3).<br>• <b>Incorrect:</b> The other options make mistakes by either adding probabilities instead of multiplying, or by incorrectly simplifying the conditional dependencies (e.g., assuming a word only depends on the single word before it, which is the Markov assumption, not the full chain rule)." },
                { question: "Which assumption allows n-gram models to reduce computation?", options: ["Bayes Assumption", "Chain Rule", "Independence Assumption", "Markov Assumption"], correctAnswer: "Markov Assumption", explanation: "<b>Fundamental Concept: The Markov Assumption.</b> The full chain rule is computationally expensive because the context for each word grows. The Markov Assumption is a simplifying strategy that assumes the future is independent of the distant past, given the recent past. In language modeling, this means we assume the probability of a word depends only on a fixed window of `n-1` preceding words.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> The Markov assumption is precisely what allows us to approximate the true conditional probability `P(w_i | w_1, ..., w_{i-1})` with the much simpler `P(w_i | w_{i-n+1}, ..., w_{i-1})`.<br>• <b>Incorrect:</b> The 'Chain Rule' is the complex reality that the Markov assumption simplifies. The 'Independence Assumption' is the most extreme form (n=1), where a word depends on nothing." },
                { question: "In a trigram language model, which of the following is a correct example of linear interpolation?", options: ["P(wi|wi-2,wi-1)=λ1P(wi|wi-2,wi-1)", "P(wi|wi-2,wi-1)=λ1P(wi|wi-2,wi-1)+λ2P(wi|wi-1)+λ3P(wi)", "P(wi|wi-2,wi-1)=max(P(wi|wi-2,wi-1),P(wi|wi-1))", "P(wi/wi-2,wi-1)=P(wi)P(wi-1)/P(wi-2)"], correctAnswer: "P(wi|wi-2,wi-1)=λ1P(wi|wi-2,wi-1)+λ2P(wi|wi-1)+λ3P(wi)", explanation: "<b>Fundamental Concept: Smoothing Techniques.</b> N-gram models often face the issue of zero probability for sequences not seen in training. Smoothing techniques address this. <b>Linear Interpolation</b> is a method that combines information from more reliable, lower-order n-gram models. It calculates a final probability as a weighted average of the trigram, bigram, and unigram probabilities.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> This formula shows the weighted sum (using lambdas λ that sum to 1) of the trigram, bigram, and unigram probabilities, which is the definition of linear interpolation.<br>• <b>Incorrect:</b> The other options represent different concepts or are mathematically incorrect." },
                { question: "A trigram model is equivalent to which order Markov model?", options: ["3", "2", "1", "4"], correctAnswer: "2", explanation: "<b>Fundamental Concept: Relationship between N-grams and Markov Models.</b> An N-gram model predicts the next word based on the `n-1` preceding words. A K-order Markov model is a system where the next state depends only on the previous `K` states. These two concepts map directly onto each other.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> A trigram model (n=3) uses the two previous words (w_i-2, w_i-1) to predict the current word (w_i). This dependence on the last <b>two</b> states makes it a <b>2nd-order</b> Markov model. The general rule is: order = n - 1.<br>• <b>Incorrect:</b> A 3rd-order Markov model would be a 4-gram model." },
                { question: "Which smoothing technique leverages the number of unique contexts a word appears in?", options: ["Good-Turing", "Add-k", "Kneser-Ney", "Absolute Discounting"], correctAnswer: "Kneser-Ney", explanation: "<b>Fundamental Concept: Advanced Smoothing.</b> While simple smoothing methods like Add-k adjust all counts uniformly, more advanced methods use more sophisticated heuristics. Kneser-Ney is based on the principle of 'diversity of context'.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> Kneser-Ney's key insight is that the probability of a word appearing in a new context is better estimated by how many *different* contexts it has already appeared in, rather than its raw frequency. It answers the question, 'How likely is this word to be a novel continuation?'<br>• <b>Incorrect:</b> The other methods are simpler: Add-k adds a constant, Absolute Discounting subtracts a constant, and Good-Turing uses frequencies of frequencies." },
                { question: "Assuming a bi-gram language model, calculate the probability of the sentence: <s> birds fly in the blue sky </s>", options: ["2/37", "1/27", "0", "1/36"], correctAnswer: "0", explanation: "<b>Fundamental Concept: N-gram Sentence Probability.</b> The probability of a sentence in an n-gram model is the product of the conditional probabilities of its n-grams. For a bigram model, this is P(w1|<s>) * P(w2|w1) * ... * P(</s>|w_n). The probability of any single bigram `P(w_i | w_{i-1})` is calculated as `Count(w_{i-1}, w_i) / Count(w_{i-1})`.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> We must find the probability of the bigram `P(sky|blue)`. We look in the corpus for the sequence 'blue sky'. It does not exist, so its count is 0. Therefore, `P(sky|blue) = 0 / Count(blue) = 0`. Since one of the terms in the multiplicative chain is 0, the entire sentence probability is 0." },
                { question: "Assuming a bi-gram language model, calculate the perplexity of the sentence: <s> birds fly in the blue sky </s>", options: ["27^(1/4)", "27^(1/5)", "9^(1/6)", "None of these"], correctAnswer: "None of these", explanation: "<b>Fundamental Concept: Perplexity and Zero Probability.</b> Perplexity is a measure of how 'surprised' a model is by a sentence. It's calculated as the Nth root of the inverse of the sentence's probability. A lower perplexity means the model was less surprised and is therefore better. A key property is how it behaves with impossible events.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> As determined previously, the probability of this sentence is 0. The perplexity calculation would involve `(1/0)^(1/N)`. Division by zero is undefined, resulting in an infinite perplexity. This signifies that the model is infinitely surprised because it encountered a sequence it deemed impossible. Therefore, no finite number can be the answer." }
            ],
            week3: [
                { question: "In backpropagation, which method is used to compute the gradients?", options: ["Gradient descent", "Chain rule of derivatives", "Matrix factorization", "Linear regression"], correctAnswer: "Chain rule of derivatives", explanation: "<b>Fundamental Concept: The Relationship Between Backpropagation, Gradients, and the Chain Rule.</b><br>1. <b>Goal:</b> To train a network, we need to adjust its weights. To do this, we need to know how a small change in each weight affects the final error. This 'effect' is the <b>gradient</b>.<br>2. <b>Algorithm:</b> <b>Backpropagation</b> is the name of the overall algorithm used to efficiently calculate all these gradients.<br>3. <b>Mathematical Tool:</b> The core mathematical engine that makes backpropagation possible is the <b>chain rule of derivatives</b>. It allows us to compute the gradient of a complex, nested function (like a neural network) by breaking it down and passing derivatives backward through the layers.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> The question asks for the *method* used to *compute* the gradients within backpropagation, which is the chain rule.<br>• <b>Incorrect:</b> 'Gradient descent' is the optimization step that *uses* these gradients to update weights; it doesn't compute them." },
                { question: "Which of the following functions is not differentiable at zero?", options: ["Sigmoid", "Tanh", "ReLU", "Linear"], correctAnswer: "ReLU", explanation: "<b>Fundamental Concept: Differentiability.</b> A function is differentiable at a point if it is 'smooth' at that point, meaning it has a single, well-defined tangent line (slope). If a function has a sharp corner or 'kink', it is not differentiable at that point.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> The ReLU function, `f(x) = max(0, x)`, has a sharp corner at x=0. To the left, its slope is 0; to the right, its slope is 1. At the exact point x=0, the slope is undefined, so it is not differentiable.<br>• <b>Incorrect:</b> 'Sigmoid', 'Tanh', and 'Linear' functions are all smooth curves without any sharp corners, making them differentiable everywhere." },
                { question: "In the context of regularization, which of the following statements is true?", options: ["L2 regularization tends to produce sparse weights", "Dropout is applied during inference to improve accuracy", "L1 regularization adds the squared weight penalties to the loss function", "Dropout prevents overfitting by randomly disabling neurons during training"], correctAnswer: "Dropout prevents overfitting by randomly disabling neurons during training", explanation: "<b>Fundamental Concept: Regularization.</b> Regularization is a collection of techniques used to prevent a model from overfitting, which is when it learns the training data too well and fails to generalize to new, unseen data. The goal is to reduce model complexity.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> <b>Dropout</b> is a regularization technique where, during training, a random fraction of neurons are ignored. This forces the network to build more robust and redundant pathways instead of relying on a few specific neurons.<br>• <b>Incorrect:</b> <b>L1 regularization</b> (not L2) produces sparse weights. Dropout is only used during <b>training</b>, not inference. L1 regularization adds the <b>absolute value</b> of weights as a penalty, while L2 adds the <b>squared</b> value." },
                { question: "Which activation function is least likely to suffer from vanishing gradients?", options: ["Tanh", "Sigmoid", "ReLU"], correctAnswer: "ReLU", explanation: "<b>Fundamental Concept: The Vanishing Gradient Problem.</b> During backpropagation, gradients are multiplied as they pass from layer to layer. If the derivative of the activation function is consistently less than 1, these repeated multiplications can cause the gradient to shrink exponentially, becoming so small that the early layers of the network stop learning effectively.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> For any positive input, the derivative of <b>ReLU</b> is exactly 1. This means the gradient can pass through many layers without shrinking, effectively solving the vanishing gradient problem for active neurons.<br>• <b>Incorrect:</b> Both <b>Sigmoid</b> and <b>Tanh</b> have derivatives that are always less than 1, making them susceptible to vanishing gradients in deep networks." },
                { question: "Which of the following equations correctly represents the derivative of the sigmoid function?", options: ["σ(x)⋅(1+σ(x))", "σ(x)²", "σ(x)⋅(1−σ(x))", "1/(1+e^x)"], correctAnswer: "σ(x)⋅(1−σ(x))", explanation: "<b>Fundamental Concept: Properties of Activation Functions.</b> Each activation function has a specific mathematical definition and a corresponding derivative, which is crucial for backpropagation. The sigmoid function is defined as `σ(x) = 1 / (1 + e^-x)`.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> Through calculus, the derivative of the sigmoid function can be shown to be `σ(x) * (1 - σ(x))`. This elegant property means that if you have already computed the output of the sigmoid function during the forward pass, you can easily calculate its gradient for the backward pass without extra complex calculations.<br>• <b>Incorrect:</b> The other options are mathematically incorrect. `1/(1+e^x)` is the function itself, not its derivative." },
                { question: "What condition must be met for the Perceptron learning algorithm to converge?", options: ["Learning rate must be zero", "Data must be non-linearly separable", "Data must be linearly separable", "Activation function must be sigmoid"], correctAnswer: "Data must be linearly separable", explanation: "<b>Fundamental Concept: The Perceptron and Linear Separability.</b> A single Perceptron is a linear classifier; it can only learn to separate data with a single straight line (or a flat plane in higher dimensions). The <b>Perceptron Convergence Theorem</b> is a formal proof that establishes the condition under which its learning algorithm is guaranteed to succeed.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> The theorem states that the algorithm will find a solution and terminate in a finite number of steps if, and only if, the data is <b>linearly separable</b>.<br>• <b>Incorrect:</b> If the data is 'non-linearly separable', the algorithm will never find a perfect solution and will fail to converge. The learning rate must be a positive value. The classic Perceptron uses a simple step function, not a sigmoid." },
                { question: "Which of the following logic functions requires a network with at least one hidden layer to model?", options: ["AND", "OR", "NOT", "XOR"], correctAnswer: "XOR", explanation: "<b>Fundamental Concept: Linear vs. Non-linear Problems.</b> A key milestone in AI history was understanding the limitations of single-layer networks. They can only solve linearly separable problems. A problem is linearly separable if you can draw a single straight line to divide the 'true' cases from the 'false' cases.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> The <b>XOR</b> function is not linearly separable. You cannot draw one straight line to separate its outputs. This failure proved that a more complex model was needed, leading to the development of Multi-Layer Perceptrons (MLPs) with hidden layers.<br>• <b>Incorrect:</b> The 'AND', 'OR', and 'NOT' functions are all linearly separable and can be solved by a single Perceptron." },
                { question: "Why is it necessary to include non-linear activation functions between layers in an MLP?", options: ["Without them, the network is just a linear function", "They prevent overfitting", "They allow backpropagation to work"], correctAnswer: "Without them, the network is just a linear function", explanation: "<b>Fundamental Concept: The Role of Non-Linearity.</b> A neural network's power comes from its ability to approximate any complex function. This is only possible if it can create non-linear decision boundaries. A linear function (like `y = mx + c`) can be represented by a matrix multiplication. Stacking multiple linear functions is equivalent to multiplying their matrices, which results in just another single linear function.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> Without non-linear activation functions, a deep network, no matter how many layers it has, collapses into a single linear model. The non-linearity is what allows each layer to learn progressively more complex features from the output of the previous one.<br>• <b>Incorrect:</b> Their primary role is not regularization or enabling backpropagation (which works on linear functions too); it is to introduce the necessary complexity." },
                { question: "What is typically the output activation function for an MLP solving a binary classification task?", options: ["Tanh", "ReLU", "Sigmoid", "Softmax"], correctAnswer: "Sigmoid", explanation: "<b>Fundamental Concept: Matching Output Function to Task.</b> The activation function in the final layer must be chosen to produce output in the desired format for the task.<br>• <b>Binary Classification:</b> The goal is to predict a single probability (a value between 0 and 1).<br>• <b>Multi-class Classification:</b> The goal is to predict a probability distribution across multiple classes (all outputs are between 0 and 1 and sum to 1).<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> The <b>Sigmoid</b> function is perfect for binary classification because it squashes any real number into the (0, 1) range.<br>• <b>Incorrect:</b> <b>Softmax</b> is used for multi-class tasks. <b>ReLU</b> and <b>Tanh</b> are typically used in hidden layers because their outputs are not constrained to a probability-like range." },
                { question: "Which type of regularization encourages sparsity in the weights?", options: ["L1 regularization", "L2 regularization", "Dropout", "Early stopping"], correctAnswer: "L1 regularization", explanation: "<b>Fundamental Concept: Regularization and Weight Penalties.</b> Regularization techniques add a penalty term to the loss function to discourage model complexity. The type of penalty determines the effect on the weights.<br>• <b>L1 Regularization (Lasso):</b> Adds a penalty proportional to the <b>absolute value</b> of the weights (`λ * |w|`).<br>• <b>L2 Regularization (Ridge):</b> Adds a penalty proportional to the <b>squared value</b> of the weights (`λ * w^2`).<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> The L1 penalty has the effect of pushing the weights of less important features to become exactly zero. This creates a 'sparse' model and acts as a form of automatic feature selection.<br>• <b>Incorrect:</b> L2 regularization forces weights to be small but rarely drives them to exactly zero. Dropout and Early Stopping are other regularization methods that do not work by directly penalizing weight magnitudes in this way." }
            ],
            week4: [
                { question: "A one-hot vector representation captures semantic similarity between related words like \"king\" and \"queen\".", options: ["True", "False"], correctAnswer: "False", explanation: "<b>Fundamental Concept: One-Hot Encoding and Vector Similarity.</b> One-hot vectors represent words as long vectors of zeros with a single '1' at a unique index for each word. Semantic similarity between vectors is measured by their closeness in vector space (e.g., using cosine similarity).<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> The statement is 'False'. Because every one-hot vector is perpendicular (orthogonal) to every other one, the cosine similarity between any two different words, like 'king' and 'queen', is always 0. This means one-hot encoding fails to capture any notion of semantic relationship.<br>• <b>Incorrect:</b> 'True' would imply that the vectors for 'king' and 'queen' are somehow closer than the vectors for 'king' and 'apple', which is not the case with one-hot encoding." },
                { question: "Which method is used to reduce the dimensionality of a term-context matrix in count-based word representations?", options: ["Principal Component Analysis", "Matrix Inversion", "Singular Value Decomposition (SVD)", "Latent Dirichlet Allocation"], correctAnswer: "Singular Value Decomposition (SVD)", explanation: "<b>Fundamental Concept: Count-Based Embeddings and Dimensionality Reduction.</b> Count-based methods (like creating a term-context matrix) result in very large, sparse matrices. To get dense, useful word embeddings, we need to reduce the dimensionality of this matrix while preserving as much of the important variance as possible. <b>Singular Value Decomposition (SVD)</b> is a powerful linear algebra technique that does exactly this by factorizing the matrix into three smaller, denser matrices.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> SVD is the standard method used in classic count-based embedding techniques like Latent Semantic Analysis (LSA) to derive dense word vectors.<br>• <b>Incorrect:</b> PCA is also a dimensionality reduction technique but SVD is more general and directly applicable here. LDA is a topic modeling algorithm. Matrix inversion is not a dimensionality reduction technique." },
                { question: "Which property makes tf-idf a better representation than raw term frequency?", options: ["It is non-linear", "It accounts for the informativeness of words", "It penalizes longer documents", "It uses hierarchical clustering"], correctAnswer: "It accounts for the informativeness of words", explanation: "<b>Fundamental Concept: TF-IDF (Term Frequency-Inverse Document Frequency).</b> The goal of TF-IDF is to measure how important a word is to a document in a collection of documents.<br>• <b>Term Frequency (TF):</b> How often a word appears in a document. This alone is not enough, as common words like 'the' would get the highest scores.<br>• <b>Inverse Document Frequency (IDF):</b> A penalty for words that are common across all documents. Words like 'the' appear everywhere and get a low IDF score, while rare, specific words get a high IDF score.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> By multiplying TF and IDF, the final score gives higher weight to words that are frequent in a *specific* document but rare overall, thus capturing their 'informativeness'.<br>• <b>Incorrect:</b> TF-IDF is a linear weighting scheme. While some normalizations can penalize longer documents, its primary purpose is measuring informativeness." },
                { question: "What is the purpose of using negative sampling in Word2Vec training?", options: ["To reduce dimensionality of word vectors", "To ensure gradient convergence", "To balance class distribution in classification", "To simplify softmax computation"], correctAnswer: "To simplify softmax computation", explanation: "<b>Fundamental Concept: The Softmax Bottleneck.</b> The original Word2Vec model used a softmax function in the output layer to calculate the probability of a context word. The softmax requires summing over the entire vocabulary (which can be huge), making it extremely computationally expensive for every single training step. <b>Negative Sampling</b> was introduced as a more efficient alternative.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> Instead of a massive multi-class classification problem, negative sampling reframes it as a simple binary classification problem: 'Is this word a true context word or a randomly sampled negative example?'. This avoids the costly softmax calculation and makes training much faster.<br>• <b>Incorrect:</b> It does not reduce dimensionality or directly ensure convergence, and while it involves classification, its main goal is efficiency, not class balance." },
                { question: "In skip-gram Word2Vec, the model:", options: ["Predicts a word given its context", "Predicts the next sentence", "Predicts surrounding context words given a target word", "Learns n-gram frequencies"], correctAnswer: "Predicts surrounding context words given a target word", explanation: "<b>Fundamental Concept: Word2Vec Architectures.</b> Word2Vec has two main architectures that learn embeddings by solving a 'fake' prediction task.<br>1. <b>CBOW (Continuous Bag-of-Words):</b> The model is given the context words (e.g., 'the cat ___ on') and must predict the target word ('sat').<br>2. <b>Skip-gram:</b> The model is given the target word ('sat') and must predict the surrounding context words ('the', 'cat', 'on').<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> The question asks about skip-gram, which takes a target word as input and predicts the context.<br>• <b>Incorrect:</b> 'Predicts a word given its context' describes the CBOW model. The other options describe different NLP tasks." },
                { question: "Why does SVD-based word embedding struggle with adding new words to the vocabulary?", options: ["It uses online learning", "It lacks semantic interpretability", "It assumes word order", "It is computationally expensive to retrain"], correctAnswer: "It is computationally expensive to retrain", explanation: "<b>Fundamental Concept: SVD and Matrix Factorization.</b> SVD-based methods (like LSA) work by performing a massive matrix factorization on the entire co-occurrence matrix of the corpus. This is a batch process that must be done on all the data at once.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> If a new word is added to the vocabulary, the dimensions of the co-occurrence matrix change. This invalidates the previous SVD calculation. You cannot simply 'update' the factorization; you must perform the entire computationally expensive SVD process again from scratch on the new, larger matrix.<br>• <b>Incorrect:</b> It uses batch learning, not online learning. Word order is a separate issue. Semantic interpretability is a general challenge, not specific to this problem." },
                { question: "Which of the following best describes the term \"distributional hypothesis\" in NLP?", options: ["Words with high frequency have greater meaning", "Words are defined by their part-of-speech tags", "A word's meaning is characterized by the words around it", "Words should be normalized before vectorization"], correctAnswer: "A word's meaning is characterized by the words around it", explanation: "<b>Fundamental Concept: The Distributional Hypothesis.</b> This is a foundational principle of modern NLP and semantics, often summarized as 'You shall know a word by the company it keeps.' It posits that words that appear in similar linguistic contexts tend to have similar meanings. This is the core idea that allows us to represent word meaning computationally.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> This option is a direct and accurate definition of the hypothesis.<br>• <b>Incorrect:</b> The other options describe different concepts in NLP, such as frequency analysis, part-of-speech tagging, and text preprocessing, none of which define the distributional hypothesis." },
                { question: "In Word2Vec, similarity between word vectors is computed using Euclidean distance.", options: ["True", "False"], correctAnswer: "False", explanation: "<b>Fundamental Concept: Measuring Vector Similarity.</b> In high-dimensional spaces, the orientation of vectors is often more important than their magnitude. <b>Cosine Similarity</b> measures the cosine of the angle between two vectors. It ranges from -1 (opposite directions) to 1 (same direction), with 0 indicating orthogonality. It is the standard way to measure similarity between word embeddings.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> The statement is 'False'. While Euclidean distance measures the straight-line distance between the endpoints of two vectors, it is sensitive to vector magnitude, which is not desirable for comparing word meanings. Cosine similarity is used instead.<br>• <b>Incorrect:</b> 'True' is incorrect because Euclidean distance is not the standard or most effective metric for this task." },
                { question: "Which method solves the problem of OOV (Out-Of-Vocabulary) words better?", options: ["One-hot encoding", "CBOW", "Skip-gram with subsampling", "FastText embedding"], correctAnswer: "FastText embedding", explanation: "<b>Fundamental Concept: Handling Out-of-Vocabulary (OOV) Words.</b> Most word embedding models like Word2Vec (CBOW, Skip-gram) learn a single vector for each unique word in the training vocabulary. If a word was not seen during training, the model has no vector for it (it's an OOV word). <b>FastText</b> was designed to solve this.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> FastText represents each word as a bag of character n-grams (e.g., 'apple' might be represented by 'app', 'ppl', 'ple', etc.). This allows it to construct a vector for an OOV word by summing the vectors of its constituent character n-grams. This is far more robust than having no representation at all.<br>• <b>Incorrect:</b> One-hot encoding, CBOW, and Skip-gram all fail to handle OOV words gracefully." },
                { question: "If the word \"economy\" occurs 4 times in a corpus, and \"growth\" appears in a window of 5 words around it 3 times, what is the entry for (economy, growth) in a term-context matrix?", options: ["1", "2", "3", "4"], correctAnswer: "3", explanation: "<b>Fundamental Concept: Term-Context Co-occurrence Matrix.</b> This is a count-based method where the matrix represents how often words appear near each other. The rows typically represent target words, and the columns represent context words. The value at `Matrix[row, column]` is the number of times the column word appeared in the context window of the row word.<br><br><b>Applying the Concept:</b><br>• <b>Correct:</b> The question asks for the entry for the target word 'economy' and the context word 'growth'. We are explicitly told that 'growth' appears in the context window of 'economy' 3 times. Therefore, the value in the matrix at the cell (economy, growth) is 3.<br>• <b>Incorrect:</b> The total number of occurrences of 'economy' (4) would be relevant for calculating probabilities, but not for the raw count in the co-occurrence matrix." }
            ]
        };
        
        // --- PAGE NAVIGATION & RENDER LOGIC ---
        const navButtons = document.querySelectorAll('.nav-button');
        const pages = document.querySelectorAll('.page');
        const quizDropdown = document.getElementById('quiz-dropdown');
        const quizContainer = document.getElementById('quiz-container');
        const quizTitle = document.getElementById('quiz-title');
        const homeGrid = document.getElementById('home-grid');

        function showPage(pageId) {
            pages.forEach(page => page.classList.toggle('active', page.id === `page-${pageId}`));
            navButtons.forEach(button => {
                const buttonPage = button.dataset.page;
                let isActive = (buttonPage === pageId);
                // Special case for assignments page
                if (pageId === 'assignments' && button.parentElement.classList.contains('dropdown')) {
                    isActive = true;
                }
                button.classList.toggle('active', isActive);
            });
        }

        function renderAssignments(weekKey) {
            quizContainer.innerHTML = ''; // Clear previous content
            const weekData = allQuizData[weekKey];
            quizTitle.textContent = `Week ${weekKey.replace('week', '')} Assignment`;
            
            if (!weekData) {
                quizContainer.innerHTML = `<p class="text-center text-gray-400 text-xl mt-10">Assignment for this week has not been released yet.</p>`;
                showPage('assignments');
                return;
            }

            weekData.forEach((item, index) => {
                const card = document.createElement('div');
                card.className = 'question-card bg-gray-800/50 backdrop-blur-sm border border-gray-700 rounded-xl p-6 mb-4';
                
                const correctAnswers = Array.isArray(item.correctAnswer) ? item.correctAnswer : [item.correctAnswer];

                card.innerHTML = `
                    <p class="text-lg font-semibold text-white">Question ${index + 1}</p>
                    <p class="mt-1 text-gray-300 mb-4">${item.question}</p>
                    <div class="options-container">
                         <ul class="list-none mt-2 mb-4 border-t border-b border-gray-700 py-2">
                            ${item.options.map(option => `
                                <li class="py-1 px-3 rounded-md ${correctAnswers.includes(option) ? 'text-green-400 font-semibold' : 'text-gray-400'}">
                                    ${correctAnswers.includes(option) ? '<i class="fas fa-check-circle mr-2 text-green-500"></i>' : '<i class="far fa-circle mr-2 text-gray-600"></i>'}
                                    ${option}
                                </li>`).join('')}
                        </ul>
                    </div>
                    <button class="toggle-explanation-btn w-full text-left text-blue-400 hover:text-blue-300 font-semibold">
                        <span class="mr-2">Show Explanation</span><i class="fas fa-chevron-down toggle-icon inline-block"></i>
                    </button>
                    <div class="explanation-content">
                        <div class="mt-2 text-gray-300 border-t border-gray-700 pt-4">${item.explanation}</div>
                    </div>`;
                quizContainer.appendChild(card);
            });
            showPage('assignments');
        }
        
        function renderHome() {
            homeGrid.innerHTML = '';
            for (let i = 1; i <= 12; i++) {
                const weekKey = `week${i}`;
                const isReleased = !!allQuizData[weekKey];
                const card = document.createElement('div');
                card.className = `week-card rounded-lg p-6 text-center ${isReleased ? 'cursor-pointer' : 'disabled'}`;
                if (isReleased) {
                    card.dataset.week = weekKey;
                }

                card.innerHTML = `
                    <i class="fas ${isReleased ? 'fa-book-open text-blue-400' : 'fa-lock text-gray-500'} text-4xl mb-4"></i>
                    <h3 class="text-xl font-bold text-white">Week ${i}</h3>
                    <p class="text-sm text-gray-400">${isReleased ? 'Assignment' : 'Assignment not released'}</p>
                `;
                homeGrid.appendChild(card);
            }
        }

        // --- SETUP & EVENT LISTENERS ---
        document.addEventListener('DOMContentLoaded', () => {
            // Populate dropdown
            for (let i = 1; i <= 12; i++) {
                const link = document.createElement('a');
                link.href = "#";
                link.dataset.week = `week${i}`;
                link.textContent = `Week ${i}`;
                link.className = "quiz-week-link block px-4 py-2 text-sm text-gray-300 hover:bg-gray-700";
                quizDropdown.appendChild(link);
            }

            // Nav button listeners
            navButtons.forEach(button => {
                if (!button.parentElement.classList.contains('dropdown')) {
                    button.addEventListener('click', () => showPage(button.dataset.page));
                }
            });
            
            // Dropdown link listeners
            quizDropdown.addEventListener('click', e => {
                e.preventDefault();
                if (e.target.matches('.quiz-week-link')) {
                    renderAssignments(e.target.dataset.week);
                }
            });
            
            // Home grid listener
            homeGrid.addEventListener('click', e => {
                const card = e.target.closest('.week-card');
                if (card && card.dataset.week) {
                    renderAssignments(card.dataset.week);
                }
            });

            // Assignment page listeners
            quizContainer.addEventListener('click', e => {
                const button = e.target.closest('.toggle-explanation-btn');
                if (button) {
                    const card = button.closest('.question-card');
                    card.classList.toggle('open');
                    button.querySelector('span').textContent = card.classList.contains('open') ? 'Hide Explanation' : 'Show Explanation';
                }
            });

            // Initial render
            renderHome();
            showPage('home'); // Show the home page by default
        });
    </script>
</body>
</html>
